
ß
Ωvoid wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)`Ä*2¿8Ö1@Ö1HÖ1Xb@gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropFilterhu≥™&B
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4::Params)ˇ ÄÄ*Ä2Ñ8É∞@É∞HÉ∞Xb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputh
^
ampere_gcgemm_64x64_ntzÄ¿*Ä2†8Å@Ä¯HÅÄXbsequential_2/conv2d_13/Conv2DhuMUB
ß
Ωvoid wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)TÄ*2Ä8Å†@Å†HÅ†Xb@gradient_tape/sequential_2/conv2d_12/Conv2D/Conv2DBackpropFilterhu≥™&B
î
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)@ ¿ò*Ä2Ä8Å∏
@Ä»HÄÿXbsequential_2/conv2d_13/Conv2DhuZUÖB
º
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Å»	@Å»	HÅ»	b8gradient_tape/sequential_2/conv2d_12/Sigmoid/SigmoidGradhuZUÖB
Ë
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2Ä8Å@ÄòHÄ†Xbsequential_2/conv2d_13/Conv2DhuZUÖB
º
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Å»@Å»HÅ»b8gradient_tape/sequential_2/conv2d_13/Sigmoid/SigmoidGradhuZUÖB
ê
Hcudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1~ÄÄ*Ä2Ä8Åò@ÅòHÅòXbsequential_2/conv2d_15/Conv2DhuMUB
ÎS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28Åÿ@ÅÿHÅÿXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterh
õ
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*Ä2T8ÅÄ@ÅÄHÅÄbsequential_2/conv2d_12/BiasAddhuZUÖB
ñ
∞void cutlass_cudnn_train::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x64_16x10_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x64_16x10_nhwc_align4::Params)| ÄÄ*Ä2	8ÄÄ@ÄÄHÄÄXb@gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropFilterh
õ
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Äƒ*Ä2@ 8Ä@ÄHÄb>gradient_tape/sequential_2/max_pooling2d_6/MaxPool/MaxPoolGradhuZUÖB
ﬁ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä2~8Åÿ@ÅÿHÅÿbsequential_2/conv2d_12/SigmoidhuZUÖB
}
4cudnn_infer_ampere_scudnn_128x64_relu_interior_nn_v1ÄÄÄ*Ä2“8Ä–@Ä–HÄ–Xbsequential_2/conv2d_14/Conv2DhuMUB
É
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2q@8Ä»@Ä»HÄ»Xb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
ë

≤	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::MaxReducer<float, 0>, long>(Eigen::internal::MaxReducer<float, 0>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)0*Ä28Å¿@Å¿HÅ¿b:categorical_crossentropy/softmax_cross_entropy_with_logitshu¶™¶B
{
4cudnn_infer_ampere_scudnn_128x32_relu_interior_nn_v1ÄÄ**@2à8Äê@ÄêHÄêXbsequential_2/conv2d_12/Conv2DhuMUB
õ
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*Ä2T8Å¯@Å¯HÅ¯bsequential_2/conv2d_13/BiasAddhuZUÖB
ﬁ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä2~8ÄË@ÄËHÄËbsequential_2/conv2d_13/SigmoidhuZUÖB
É
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2b@8Å‡@Å‡HÅ‡Xb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2“8Åê@ÅêHÅêXb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputh
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2à8Ä‡@Ä‡HÄ‡Xb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputh
ª
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2`8Å†@Å†HÅ†b8gradient_tape/sequential_2/conv2d_13/BiasAdd/BiasAddGradhuZUÖB

§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*‡2@8Å¯@Å¯HÅ¯b$sequential_2/max_pooling2d_6/MaxPoolhu  ØB
√
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)`Ä*2	@8Ä–@Ä–HÄ–Xb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputhu≥™&B
º
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ä¿@Ä¿HÄ¿b8gradient_tape/sequential_2/conv2d_14/Sigmoid/SigmoidGradhuZUÖB
Î
ãvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float) 0*Ä2Ä8Ä∞@Ä∞HÄ∞b8gradient_tape/sequential_2/conv2d_12/BiasAdd/BiasAddGradhu  »B
º
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Äê@ÄêHÄêb8gradient_tape/sequential_2/conv2d_15/Sigmoid/SigmoidGradhuZUÖB
Ç

£	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
∂
◊void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Ä‡@Ä‡HÄ‡b:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Å–@Å–HÅ–Xb@gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropFilterhu  »B
õ
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*Ä2T8Å–@Å–HÅ–bsequential_2/conv2d_14/BiasAddhuZUÖB
ﬁ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä2~8Ä–@Ä–HÄ–bsequential_2/conv2d_14/SigmoidhuZUÖB
É
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Å»@Å»HÅ»Xb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Å»@Å»HÅ»Xb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
É
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä»@Ä»HÄ»Xb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
ö
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä$*Ä2@@8Ä∏@Ä∏HÄ∏b>gradient_tape/sequential_2/max_pooling2d_7/MaxPool/MaxPoolGradhu  »B
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä†@Ä†HÄ†Xb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
Å
ampere_sgemm_128x128_ntvÄÄ*Ä2$8Äò@ÄòHÄòXb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhuMUB
ﬁ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä2~8Äò@ÄòHÄòbsequential_2/conv2d_15/SigmoidhuZUÖB
É
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Äà@ÄàHÄàXb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
õ
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*Ä2T8Äà@ÄàHÄàbsequential_2/conv2d_15/BiasAddhuZUÖB
ˇ
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2T8Äÿ@ÄÿHÄÿb%Adam/Adam/update_12/ResourceApplyAdamhuZUÖB
ÎS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28Ä–@Ä–HÄ–Xb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä»@Ä»HÄ»Xb@gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropFilterhu  »B
Å
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Å∞@Å∞HÅ∞b8gradient_tape/sequential_2/conv2d_14/BiasAdd/BiasAddGradhu  »B
É
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä∞@Ä∞HÄ∞Xb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B

§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*ê2@8Ä∞@Ä∞HÄ∞b$sequential_2/max_pooling2d_7/MaxPoolhu ¿®B
Æ
»void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params)v ÄÄ*Ä2ê8Ä∞@Ä∞HÄ∞Xb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputh
õ
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä*Ä2@Ä8Ä®@Ä®HÄ®b>gradient_tape/sequential_2/max_pooling2d_8/MaxPool/MaxPoolGradhu  »B
Å
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Ä†@Ä†HÄ†b8gradient_tape/sequential_2/conv2d_15/BiasAdd/BiasAddGradhu  »B
π
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä`*Ä2Ä8Äê@ÄêHÄêbfgradient_tape/sequential_2/conv2d_12/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizerhuZUÖB
Ù
∞void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params)¢ Ä¿*Ä228Åà@ÅàHÅàXbsequential_2/conv2d_16/Conv2Dh
Ù
∞void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params)¢ Ä¿*Ä2@8ÄÄ@ÄÄHÄÄXbsequential_2/conv2d_17/Conv2Dh
≥
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28Äx@ÄxHÄxbArgMaxhuZUÖB
„
ûvoid fft2d_r2c_32x32<float, false, 5u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2@8Äp@ÄpHÄpXbsequential_2/conv2d_13/Conv2DhuZUÖB
Ê
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)@ÄÑ*Ä2@8Å`@Å`HÅ`Xb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhuZUÖB
Ï
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)@ÄH* 28ÄP@ÄPHÄPXb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhuZUÖB
«
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params)^ ÄÄ*Ä28ÄP@ÄPHÄPXbsequential_2/dense_4/MatMulhugUÖA
π
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8ÄP@ÄPHÄPb8gradient_tape/sequential_2/conv2d_17/BiasAdd/BiasAddGradhuZUÖB
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8ÅH@ÅHHÅHXb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
µ
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28ÄH@ÄHHÄHbArgMax_1huZUÖB
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8ÄH@ÄHHÄHXb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
‰
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)@Ä¡*Ä2@8ÄH@ÄHHÄHXb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhuZUÖB
π
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ä@@Ä@HÄ@b8gradient_tape/sequential_2/conv2d_16/Sigmoid/SigmoidGradhuZUÖB
”
Üvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4::Params)î Ä¿*Ä2@8Ä@@Ä@HÄ@b+gradient_tape/sequential_2/dense_4/MatMul_1h
’
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4::Params)Z ÄÄ*Ä28Ä@@Ä@HÄ@Xb)gradient_tape/sequential_2/dense_4/MatMulhugUÖA
’
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4::Params)Z ÄÄ*Ä28Å8@Å8HÅ8Xb)gradient_tape/sequential_2/dense_5/MatMulhugUÖA
π
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8Ä8@Ä8HÄ8b8gradient_tape/sequential_2/conv2d_16/BiasAdd/BiasAddGradhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Å0@Å0HÅ0b$Adam/Adam/update_8/ResourceApplyAdamhuZUÖB
ﬁ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä0@Ä0HÄ0Xbsequential_2/conv2d_16/Conv2Dhu  »B
ò
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*Ä2T8Ä0@Ä0HÄ0bsequential_2/conv2d_17/BiasAddhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä0@Ä0HÄ0b$Adam/Adam/update_4/ResourceApplyAdamhuZUÖB
«
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params)^ ÄÄ*Ä28Å(@Å(HÅ(Xbsequential_2/dense_5/MatMulhugUÖA
π
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ä(@Ä(HÄ(b8gradient_tape/sequential_2/conv2d_17/Sigmoid/SigmoidGradhuZUÖB
≈
Èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long).*Ä28Ä(@Ä(HÄ(b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
Ä
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä(@Ä(HÄ(Xb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
Ï
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä * 2@8Ä(@Ä(HÄ(b$sequential_2/max_pooling2d_8/MaxPoolhu  »B
’
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4::Params)\ ÄÄ*Ä28Ä(@Ä(HÄ(b+gradient_tape/sequential_2/dense_5/MatMul_1hugUÖA
ò
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*Ä2T8Ä(@Ä(HÄ(bsequential_2/conv2d_16/BiasAddhuZUÖB
˘
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b"Adam/Adam/update/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b$Adam/Adam/update_2/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Ä(@Ä(HÄ(b$Adam/Adam/update_6/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä228Ä(@Ä(HÄ(b%Adam/Adam/update_14/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2H8Ä(@Ä(HÄ(b%Adam/Adam/update_10/ResourceApplyAdamhuZUÖB
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Ä(@Ä(HÄ(bdgradient_tape/sequential_2/max_pooling2d_8/MaxPool/MaxPoolGrad-2-TransposeNHWCToNCHW-LayoutOptimizerhu  »B
F
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä @Ä HÄ bCasthu  »B
€
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä2~8Ä @Ä HÄ bsequential_2/conv2d_16/SigmoidhuZUÖB
€
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä2~8Ä @Ä HÄ bsequential_2/conv2d_17/SigmoidhuZUÖB
ˇ	
£	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)&*Ä28Ä @Ä HÄ b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
≠
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)(*Ä28Ä @Ä HÄ b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
°
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä @Ä HÄ Xbsequential_2/conv2d_12/Conv2Dhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
ﬁ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä @Ä HÄ Xbsequential_2/conv2d_17/Conv2Dhu  »B
ﬁ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä @Ä HÄ Xbsequential_2/conv2d_17/Conv2Dhu  »B
ﬁ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä @Ä HÄ Xbsequential_2/conv2d_16/Conv2Dhu  »B
Ø
Lvoid cudnn::ops::scalePackedTensor_kernel<float, float>(long, float*, float)*Ä2¿8Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputhu  »B
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
œ
ëvoid tensorflow::(anonymous namespace)::GenerateNormalizedProb<float, float, 4>(float const*, float const*, float const*, float*, int, int, bool) *Ä28Ä @Ä HÄ bsequential_2/dense_5/Softmaxhu  »B
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_1/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b%Adam/Adam/update_13/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_9/ResourceApplyAdamhuZUÖB
É
≈void tensorflow::functor::RowReduceKernel<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, cub::Sum>(cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, int, int, cub::Sum, std::iterator_traits<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long> >::value_type)*Ä28Ä @Ä HÄ bsequential_2/dense_5/Softmaxhu  »B
∆
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbsequential_2/conv2d_12/Conv2DhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhuZUÖB
∆
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbsequential_2/conv2d_14/Conv2DhuZUÖB
∆
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbsequential_2/conv2d_13/Conv2DhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhuZUÖB
∆
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xbsequential_2/conv2d_15/Conv2DhuZUÖB
∆
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xbsequential_2/conv2d_16/Conv2DhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputhuZUÖB
∆
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xbsequential_2/conv2d_17/Conv2DhuZUÖB
ö
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Ä @Ä HÄ bLsequential_2/max_pooling2d_8/MaxPool-0-2-TransposeNCHWToNHWC-LayoutOptimizerhu  »B
K
"AddV2_GPU_DT_INT64_DT_INT64_kernel*Ä28Ä@ÄHÄbAdam/addhuZUÖB
H
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_3hu  »B
z
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄb8categorical_crossentropy/weighted_loss/num_elements/Casthu  »B
K
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄb
Adam/Pow_1huZUÖB
‡
Évoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä28Ä@ÄHÄb;gradient_tape/categorical_crossentropy/weighted_loss/Tile_1huZUÖB
°
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb,categorical_crossentropy/weighted_loss/valuehuZUÖB
ˇ
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb
div_no_nanhuZUÖB
∫
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbEgradient_tape/categorical_crossentropy/weighted_loss/value/div_no_nanhuZUÖB
∑
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sigmoid_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb6gradient_tape/sequential_2/dense_4/Sigmoid/SigmoidGradhuZUÖB
Ÿ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä28Ä@ÄHÄbsequential_2/dense_4/SigmoidhuZUÖB
ò
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOphuZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_1huZUÖB
ò
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/Adam/AssignAddVariableOphuZUÖB
ê
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_4huZUÖB
˜
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2 8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
ﬁ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXbsequential_2/conv2d_16/Conv2Dhu  »B
ﬂ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä@ÄHÄXbsequential_2/conv2d_17/Conv2Dhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropFilterhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
¿
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)(ÄD* 28Ä@ÄHÄXbsequential_2/conv2d_15/Conv2DhuZU∑B
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
‹
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2d8Ä@ÄHÄXbsequential_2/dense_5/MatMulhu  »B
›
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2Ä8Ä@ÄHÄXbsequential_2/dense_4/MatMulhu  »B
¨
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) †*Ä28Ä@ÄHÄb6gradient_tape/sequential_2/dense_5/BiasAdd/BiasAddGradhuZUÖB
¨
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) Ä*Ä28Ä@ÄHÄb6gradient_tape/sequential_2/dense_4/BiasAdd/BiasAddGradhuZUÖB
ë
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä28Ä@ÄHÄbsequential_2/dense_5/BiasAddhuZUÖB
ë
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä28Ä@ÄHÄbsequential_2/dense_4/BiasAddhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb%Adam/Adam/update_11/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb%Adam/Adam/update_15/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb$Adam/Adam/update_3/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb$Adam/Adam/update_5/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb$Adam/Adam/update_7/ResourceApplyAdamhuZUÖB
Î
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄbSum_2hu  »B
ê
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄb*categorical_crossentropy/weighted_loss/Sumhu  »B
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_12/BiasAdd/BiasAddGradhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_14/BiasAdd/BiasAddGradhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_15/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_12/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_15/BiasAdd/BiasAddGradhuZUÖB
·
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type) *Ä28Ä@ÄHÄbsequential_2/dense_5/Softmaxhu  »B
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_12/Conv2D/Conv2DBackpropFilterhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhuZUÖB
G
 Cast_GPU_DT_BOOL_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_2hu  »B
M
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/Cast_1hu  »B
_
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä228Ä@ÄHÄbcategorical_crossentropy/Casthu  »B
G
!Equal_GPU_DT_INT64_DT_BOOL_kernel*Ä28Ä@ÄHÄbEqualhuZUÖB
P
%LogicalAnd_GPU_DT_BOOL_DT_BOOL_kernel*Ä28Ä@ÄHÄb
LogicalAndhuZUÖB
D
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbMulhuZUÖB
ç
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbLgradient_tape/categorical_crossentropy/softmax_cross_entropy_with_logits/mulhuZUÖB
I
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/PowhuZUÖB
Å
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbdiv_no_nan_1huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_2huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_3huZUÖB
°
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä@ÄHÄXbsequential_2/conv2d_14/Conv2Dhu  »B
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_14/BiasAdd/BiasAddGradhuZUÖB